---
# AI CUDA Docker Setup - Ansible Playbook
# Complete setup for Ubuntu 22.04 LTS with Tesla K80 GPU, CUDA 12.2, and Docker
# Optimized for NVIDIA Tesla K80 (compute capability 3.7)
# Based on the original RX6700 setup but adapted for CUDA

- name: Setup AI System with CUDA and Docker for Tesla K80
  hosts: localhost
  connection: local
  become: yes
  vars:
    cuda_version: "11.7"
    cuda_version_full: "11-7"
    # user_name and home_dir will be provided via --extra-vars from bootstrap.sh
    # Defaults for direct playbook execution:
    user_name: "{{ user_name | default(ansible_user_id) }}"
    home_dir: "{{ home_dir | default(ansible_user_dir) }}"
    
  tasks:
    # ===============================================
    # PREREQUISITES AND VALIDATION
    # ===============================================
    
    - name: Check Ubuntu version
      assert:
        that:
          - ansible_distribution == "Ubuntu"
          - ansible_distribution_version == "22.04"
        fail_msg: "This playbook requires Ubuntu 22.04 LTS"
        success_msg: "Ubuntu 22.04 LTS confirmed"
      tags: [prerequisites]

    - name: Check for NVIDIA GPU
      shell: lspci | grep -i nvidia | grep -i vga
      register: nvidia_gpu_check
      failed_when: false
      changed_when: false
      tags: [prerequisites]

    - name: Display GPU information
      debug:
        msg: "NVIDIA GPU detected: {{ nvidia_gpu_check.stdout }}"
      when: nvidia_gpu_check.rc == 0
      tags: [prerequisites]

    - name: Warn if no NVIDIA GPU detected
      debug:
        msg: "WARNING: No NVIDIA GPU detected. CUDA installation may not work properly."
      when: nvidia_gpu_check.rc != 0
      tags: [prerequisites]

    - name: Test internet connectivity
      uri:
        url: https://google.com
        method: HEAD
        timeout: 5
      tags: [prerequisites]

    # ===============================================
    # SYSTEM PREPARATION
    # ===============================================
    
    - name: Update APT cache
      apt:
        update_cache: yes
        cache_valid_time: 3600
      tags: [system]

    - name: Upgrade all packages
      apt:
        upgrade: dist
        autoremove: yes
        autoclean: yes
      tags: [system]

    - name: Install base packages
      apt:
        name:
          - curl
          - wget
          - gnupg
          - lsb-release
          - software-properties-common
          - apt-transport-https
          - ca-certificates
          - build-essential
          - git
          - vim
          - htop
          - tree
          - unzip
          - python3
          - python3-pip
          - python3-venv
          - linux-headers-generic
          - dkms
        state: present
      tags: [system]

    - name: Remove old CUDA sources
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /etc/apt/sources.list.d/cuda.list
        - /etc/apt/keyrings/cuda.gpg
        - /etc/apt/sources.list.d/nvidia-ml.list
      tags: [cleanup]

    - name: Stop old Docker services
      systemd:
        name: "{{ item }}"
        state: stopped
      loop:
        - docker
        - docker.socket
        - containerd
      failed_when: false
      tags: [cleanup]

    - name: Remove old Docker packages
      apt:
        name:
          - docker
          - docker-engine
          - docker.io
          - containerd
          - runc
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - docker-buildx-plugin
          - docker-compose-plugin
          - nvidia-docker2
          - nvidia-container-runtime
        state: absent
      tags: [cleanup]

    - name: Remove old Docker data directories
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /var/lib/docker
        - /etc/docker
        - /var/lib/containerd
      tags: [cleanup]

    - name: Remove old CUDA installations
      file:
        path: "{{ item }}"
        state: absent
      loop:
        - /usr/local/cuda
        - /usr/local/cuda-*
      tags: [cleanup]

    # ===============================================
    # WORKSPACE DIRECTORY CREATION
    # ===============================================
    
    - name: Create AI workspace directories
      file:
        path: "{{ home_dir }}/{{ item }}"
        state: directory
        mode: '0755'
        owner: "{{ user_name }}"
        group: "{{ user_name }}"
      loop:
        - ai-workspace
        - ai-workspace/pytorch
        - ai-workspace/tensorflow
        - ai-workspace/jupyter
        - ai-workspace/shared
        - ai-workspace/datasets
        - ai-workspace/models
        - ai-workspace/projects
      tags: [workspace]

    # ===============================================
    # NVIDIA DRIVER INSTALLATION - TESLA K80 SPECIFIC
    # ===============================================
    
    - name: Check if correct NVIDIA driver is installed
      shell: nvidia-smi
      register: nvidia_driver_check
      failed_when: false
      changed_when: false
      tags: [nvidia]

    - name: Remove incompatible NVIDIA drivers (580+)
      apt:
        name:
          - nvidia-driver-580
          - nvidia-dkms-580
          - nvidia-utils-580
          - nvidia-*-580
        state: absent
        purge: yes
      tags: [nvidia]

    - name: Install required packages for NVIDIA driver installation
      apt:
        name:
          - software-properties-common
          - dkms
          - build-essential
        state: present
      tags: [nvidia]

    - name: Add NVIDIA PPA for driver availability with retry
      apt_repository:
        repo: ppa:graphics-drivers/ppa
        state: present
      register: nvidia_ppa_result
      retries: 3
      delay: 5
      until: nvidia_ppa_result is succeeded
      tags: [nvidia]

    - name: Update APT cache after adding NVIDIA PPA
      apt:
        update_cache: yes
        cache_valid_time: 0
      tags: [nvidia]

    - name: Install NVIDIA driver 470 (Tesla K80 compatible)
      apt:
        name:
          - nvidia-driver-470
          - nvidia-utils-470
          - nvidia-settings
          - nvidia-modprobe
        state: present
        install_recommends: yes
      register: nvidia_install_result
      retries: 2
      delay: 10
      until: nvidia_install_result is succeeded
      tags: [nvidia]

    - name: Hold NVIDIA driver packages to prevent auto-upgrade
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - nvidia-driver-470
        - nvidia-utils-470
      tags: [nvidia]

    - name: Blacklist nouveau driver
      lineinfile:
        path: /etc/modprobe.d/blacklist-nouveau.conf
        line: "{{ item }}"
        create: yes
      loop:
        - "blacklist nouveau"
        - "options nouveau modeset=0"
      tags: [nvidia]

    - name: Update initramfs after driver installation
      command: update-initramfs -u
      notify: reboot required
      tags: [nvidia]

    - name: Check if reboot is required for NVIDIA driver
      stat:
        path: /var/run/reboot-required
      register: reboot_required_file
      tags: [nvidia]

    - name: Force reboot if NVIDIA driver was just installed and reboot is required
      reboot:
        msg: "Rebooting to load NVIDIA driver modules"
        reboot_timeout: 300
        pre_reboot_delay: 10
        post_reboot_delay: 30
      when: 
        - nvidia_install_result is changed
        - reboot_required_file.stat.exists
      tags: [nvidia]

    - name: Verify NVIDIA driver is loaded after installation
      shell: nvidia-smi
      register: nvidia_verify
      failed_when: 
        - nvidia_verify.rc != 0 and nvidia_verify.rc != 14  # rc 14 is warning (infoROM corruption)
        - "'Tesla K80' not in nvidia_verify.stdout"         # Ensure our GPU is detected
      changed_when: false
      tags: [nvidia]

    # ===============================================
    # CUDA INSTALLATION
    # ===============================================
    
    - name: Create APT keyrings directory
      file:
        path: /etc/apt/keyrings
        state: directory
        mode: '0755'
      tags: [cuda]

    - name: Download CUDA keyring package
      get_url:
        url: "https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb"
        dest: /tmp/cuda-keyring_1.0-1_all.deb
        mode: '0644'
      tags: [cuda]

    - name: Install CUDA keyring
      apt:
        deb: /tmp/cuda-keyring_1.0-1_all.deb
        state: present
      tags: [cuda]

    - name: Update APT cache after adding CUDA repository
      apt:
        update_cache: yes
      tags: [cuda]

    - name: Remove incompatible CUDA 12.x packages
      apt:
        name:
          - cuda-toolkit-12-2
          - cuda-runtime-12-2
          - cuda-*-12-2
        state: absent
        purge: yes
      tags: [cuda]

    - name: Temporarily release NVIDIA package holds for CUDA installation
      dpkg_selections:
        name: "{{ item }}"
        selection: install
      loop:
        - nvidia-driver-470
        - nvidia-utils-470
      tags: [cuda]

    - name: Pin NVIDIA driver 470 to prevent CUDA from upgrading it
      copy:
        content: |
          Package: nvidia-driver-470 nvidia-utils-470 libnvidia-*-470
          Pin: version 470.*
          Pin-Priority: 1001
        dest: /etc/apt/preferences.d/nvidia-470-pin
        mode: '0644'
      tags: [cuda]

    - name: Try installing CUDA components individually to avoid conflicts
      apt:
        name:
          - cuda-cudart-11-7
          - cuda-nvcc-11-7
        state: present
        install_recommends: no
      register: cuda_install_result
      ignore_errors: yes
      tags: [cuda]

    - name: Install cuDNN if CUDA installation succeeded
      apt:
        name:
          - libcudnn8
          - libcudnn8-dev
        state: present
        install_recommends: no
      when: cuda_install_result is succeeded
      tags: [cuda]

    - name: Re-hold NVIDIA driver packages after CUDA installation
      dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - nvidia-driver-470
        - nvidia-utils-470
      when: cuda_install_result is succeeded
      tags: [cuda]

    - name: Create CUDA symlink
      file:
        src: "/usr/local/cuda-{{ cuda_version }}"
        dest: /usr/local/cuda
        state: link
        force: yes
      tags: [cuda]

    - name: Create CUDA environment script
      copy:
        content: |
          #!/bin/bash
          # CUDA Environment Setup
          export CUDA_HOME=/usr/local/cuda
          export PATH=$CUDA_HOME/bin:$PATH
          export LD_LIBRARY_PATH=$CUDA_HOME/lib64:${LD_LIBRARY_PATH:-}
          export CUDA_ROOT=$CUDA_HOME
          export NVIDIA_VISIBLE_DEVICES=all
          export NVIDIA_DRIVER_CAPABILITIES=compute,utility
        dest: /etc/profile.d/cuda.sh
        mode: '0755'
      tags: [cuda]

    # ===============================================
    # DOCKER INSTALLATION
    # ===============================================
    
    - name: Add Docker GPG key
      get_url:
        url: https://download.docker.com/linux/ubuntu/gpg
        dest: /tmp/docker.gpg.key
        mode: '0644'
      tags: [docker]

    - name: Import Docker GPG key
      shell: gpg --dearmor < /tmp/docker.gpg.key > /etc/apt/keyrings/docker.gpg
      args:
        creates: /etc/apt/keyrings/docker.gpg
      tags: [docker]

    - name: Add Docker repository
      apt_repository:
        repo: "deb [arch=amd64 signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
        filename: docker
        state: present
      tags: [docker]

    - name: Install Docker packages
      apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - docker-buildx-plugin
          - docker-compose-plugin
        state: present
      tags: [docker]

    # ===============================================
    # NVIDIA CONTAINER TOOLKIT
    # ===============================================
    
    - name: Add NVIDIA Container Toolkit repository
      get_url:
        url: https://nvidia.github.io/libnvidia-container/gpgkey
        dest: /tmp/nvidia-container-toolkit.gpg.key
        mode: '0644'
      tags: [nvidia-docker]

    - name: Import NVIDIA Container Toolkit GPG key
      shell: gpg --dearmor < /tmp/nvidia-container-toolkit.gpg.key > /etc/apt/keyrings/nvidia-container-toolkit.gpg
      args:
        creates: /etc/apt/keyrings/nvidia-container-toolkit.gpg
      tags: [nvidia-docker]

    - name: Add NVIDIA Container Toolkit repository
      apt_repository:
        repo: "deb [signed-by=/etc/apt/keyrings/nvidia-container-toolkit.gpg] https://nvidia.github.io/libnvidia-container/stable/ubuntu18.04/$(ARCH) /"
        filename: nvidia-container-toolkit
        state: present
      tags: [nvidia-docker]

    - name: Update APT cache
      apt:
        update_cache: yes
      tags: [nvidia-docker]

    - name: Install NVIDIA Container Toolkit
      apt:
        name:
          - nvidia-container-toolkit
        state: present
      tags: [nvidia-docker]

    - name: Configure NVIDIA Container Runtime
      shell: nvidia-ctk runtime configure --runtime=docker
      tags: [nvidia-docker]

    - name: Create Docker daemon configuration
      copy:
        content: |
          {
              "log-driver": "json-file",
              "log-opts": {
                  "max-size": "10m",
                  "max-file": "3"
              },
              "storage-driver": "overlay2",
              "runtimes": {
                  "nvidia": {
                      "path": "nvidia-container-runtime",
                      "runtimeArgs": []
                  }
              },
              "default-runtime": "nvidia",
              "default-ulimits": {
                  "memlock": {
                      "Hard": -1,
                      "Name": "memlock",
                      "Soft": -1
                  },
                  "stack": {
                      "Hard": 67108864,
                      "Name": "stack",
                      "Soft": 67108864
                  }
              }
          }
        dest: /etc/docker/daemon.json
        mode: '0644'
      notify: restart docker
      tags: [docker]

    - name: Enable and start Docker services
      systemd:
        name: "{{ item }}"
        enabled: yes
        state: started
      loop:
        - docker
        - containerd
      tags: [docker]

    # ===============================================
    # USER PERMISSIONS
    # ===============================================
    
    - name: Add user to docker group
      user:
        name: "{{ user_name }}"
        groups: docker
        append: yes
      tags: [permissions]

    # ===============================================
    # TEMPLATE AND TEST FILES
    # ===============================================
    
    - name: Get current working directory
      shell: pwd
      register: current_pwd
      become: no
      tags: [templates]

    - name: Create templates directory
      file:
        path: "{{ current_pwd.stdout }}/templates"
        state: directory
        mode: '0755'
      become: no
      tags: [templates]

    - name: Create tests directory
      file:
        path: "{{ current_pwd.stdout }}/tests"
        state: directory
        mode: '0755'
      become: no
      tags: [templates]

    - name: Create Docker Compose template
      copy:
        content: |
          services:
            jupyter-pytorch:
              image: pytorch/pytorch:1.13.1-cuda11.6-cudnn8-runtime
              container_name: ai-jupyter-pytorch
              restart: unless-stopped
              ports:
                - "8888:8888"
              volumes:
                - ${HOME}/ai-workspace:/workspace
                - ${HOME}/.jupyter:/root/.jupyter
              environment:
                - JUPYTER_ENABLE_LAB=yes
                - NVIDIA_VISIBLE_DEVICES=all
              command: >
                bash -c "pip install jupyterlab ipywidgets matplotlib seaborn pandas scikit-learn &&
                         jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root 
                         --NotebookApp.token='' --NotebookApp.password=''"
              deploy:
                resources:
                  reservations:
                    devices:
                      - driver: nvidia
                        count: all
                        capabilities: [gpu]

            jupyter-tensorflow:
              image: tensorflow/tensorflow:2.11.0-gpu-jupyter
              container_name: ai-jupyter-tensorflow
              restart: unless-stopped
              ports:
                - "8889:8888"
              volumes:
                - ${HOME}/ai-workspace:/tf/workspace
                - ${HOME}/.jupyter:/root/.jupyter
              environment:
                - JUPYTER_ENABLE_LAB=yes
                - NVIDIA_VISIBLE_DEVICES=all
              command: >
                bash -c "pip install jupyterlab matplotlib seaborn pandas scikit-learn &&
                         jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root 
                         --NotebookApp.token='' --NotebookApp.password=''"
              deploy:
                resources:
                  reservations:
                    devices:
                      - driver: nvidia
                        count: all
                        capabilities: [gpu]

            cuda-dev:
              image: nvidia/cuda:11.7.1-devel-ubuntu20.04
              container_name: ai-cuda-dev
              restart: unless-stopped
              ports:
                - "8080:8080"
              volumes:
                - ${HOME}/ai-workspace:/workspace
              environment:
                - NVIDIA_VISIBLE_DEVICES=all
              command: sleep infinity
              deploy:
                resources:
                  reservations:
                    devices:
                      - driver: nvidia
                        count: all
                        capabilities: [gpu]

            code-server:
              image: codercom/code-server:latest
              container_name: ai-code-server
              restart: unless-stopped
              ports:
                - "8443:8080"
              volumes:
                - ${HOME}/ai-workspace:/home/coder/workspace
                - ${HOME}/.config:/home/coder/.config
              environment:
                - PASSWORD=ai-development
              command: --bind-addr 0.0.0.0:8080 /home/coder/workspace

          volumes:
            ai-workspace:
              driver: local
        dest: "{{ current_pwd.stdout }}/templates/docker-compose.ai-template.yml"
        mode: '0644'
      become: no
      tags: [templates]

    - name: Create comprehensive Docker test script
      copy:
        content: |
          #!/bin/bash
          # Comprehensive Docker and CUDA testing for Tesla K80 AI system
          
          set -e
          
          echo "üß™ Tesla K80 AI Docker Comprehensive Test"
          echo "=========================================="
          
          # Store absolute script path before changing directories
          SCRIPT_PATH="$(realpath "$0")"
          
          # Navigate to templates directory where Docker Compose template is located
          SCRIPT_DIR="$(dirname "$0")"
          TEMPLATES_DIR="$SCRIPT_DIR/../templates"
          
          if [ ! -d "$TEMPLATES_DIR" ]; then
              echo "‚ùå Templates directory not found at $TEMPLATES_DIR"
              exit 1
          fi
          
          cd "$TEMPLATES_DIR"
          
          # Handle Docker permissions
          if ! docker info > /dev/null 2>&1; then
              echo "‚ùå Docker permission denied. Please run one of:"
              echo "   sudo chmod 666 /var/run/docker.sock"
              echo "   newgrp docker  # then re-run this script"
              echo "   sudo ./tests/test-cuda-docker.sh"
              exit 1
          fi
          
          # Test 1: Basic CUDA Docker functionality
          echo "‚úÖ Test 1: Basic CUDA Docker functionality..."
          echo "   Testing basic CUDA container with Tesla K80..."
          if docker run --rm --gpus all nvidia/cuda:11.7.1-devel-ubuntu20.04 nvidia-smi --query-gpu=name --format=csv,noheader; then
              echo "   ‚úÖ Basic CUDA Docker integration working"
          else
              echo "   ‚ùå Basic CUDA Docker integration failed"
              exit 1
          fi
          
          # Test 2: Docker Compose syntax validation
          echo "‚úÖ Test 2: Validating Docker Compose template syntax..."
          if docker compose -f docker-compose.ai-template.yml config > /dev/null 2>&1; then
              echo "   ‚úÖ Docker Compose syntax is valid"
          else
              echo "   ‚ùå Docker Compose syntax error"
              exit 1
          fi
          
          # Test 3: Docker Compose CUDA container functionality
          echo "‚úÖ Test 3: Testing Docker Compose CUDA development container..."
          if docker compose -f docker-compose.ai-template.yml up cuda-dev -d; then
              echo "   ‚úÖ CUDA container started successfully"
              
              # Wait for container to be ready
              sleep 3
              
              # Test GPU access inside container
              echo "   üîç Testing GPU access inside container..."
              if docker exec ai-cuda-dev nvidia-smi > /dev/null 2>&1; then
                  echo "   ‚úÖ GPU access working inside container"
                  docker exec ai-cuda-dev nvidia-smi --query-gpu=name --format=csv,noheader | sed 's/^/      /'
              else
                  echo "   ‚ùå GPU access failed inside container"
              fi
              
              # Cleanup
              docker compose -f docker-compose.ai-template.yml down cuda-dev
              echo "   ‚úÖ Container stopped and cleaned up"
          else
              echo "   ‚ùå Failed to start CUDA container"
              exit 1
          fi
          
          # Test 4: Check Docker images availability
          echo "‚úÖ Test 4: Checking Docker images availability..."
          IMAGES=(
              "nvidia/cuda:11.7.1-devel-ubuntu20.04"
              "pytorch/pytorch:1.13.1-cuda11.6-cudnn8-runtime"
              "tensorflow/tensorflow:2.11.0-gpu-jupyter"
              "codercom/code-server:latest"
          )
          
          for image in "${IMAGES[@]}"; do
              echo "   ÔøΩ Checking $image..."
              if docker manifest inspect "$image" > /dev/null 2>&1; then
                  echo "      ‚úÖ Image available"
              else
                  echo "      ‚ö†Ô∏è  Image may need to be pulled"
              fi
          done
          
          echo
          echo "üéâ Tesla K80 AI Docker Comprehensive Test Complete!"
          echo "=================================================="
          echo
          echo "üìã Summary:"
          echo "‚Ä¢ Basic CUDA Docker: ‚úÖ Working"
          echo "‚Ä¢ Docker Compose syntax: ‚úÖ Valid"
          echo "‚Ä¢ CUDA container functionality: ‚úÖ Working"
          echo "‚Ä¢ GPU access in containers: ‚úÖ Working"
          echo "‚Ä¢ Required images: ‚úÖ Available"
          echo
          echo "üöÄ You can now use the Docker Compose template:"
          echo "   cd docker && docker compose -f docker-compose.ai-template.yml up [service]"
          echo
          echo "Available services:"
          echo "‚Ä¢ jupyter-pytorch  (port 8888) - PyTorch Jupyter Lab"
          echo "‚Ä¢ jupyter-tensorflow (port 8889) - TensorFlow Jupyter Lab" 
          echo "‚Ä¢ cuda-dev (port 8080) - CUDA development environment"
          echo "‚Ä¢ code-server (port 8443) - VS Code in browser"
        dest: "{{ ansible_env.PWD }}/tests/test-cuda-docker.sh"
        mode: '0755'
      become: no
      tags: [templates]



  # ===============================================
  # HANDLERS
  # ===============================================
  
  handlers:
    - name: restart docker
      systemd:
        name: docker
        state: restarted

    - name: reboot required
      reboot:
        msg: "Rebooting to apply system changes"
        reboot_timeout: 300
        pre_reboot_delay: 10
        post_reboot_delay: 30